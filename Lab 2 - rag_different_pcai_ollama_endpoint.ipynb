{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd03dbf2-7e12-4b6d-b325-2c4f10ea2ab3",
   "metadata": {},
   "source": [
    "# RAG Using LLM Endpoints from Ollama from Tools & Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc737e3-dc25-4744-9295-7fcd26c2de29",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238302c3",
   "metadata": {},
   "source": [
    "### One-Time Environment Setup (Cert & Dependencies)\n",
    "\n",
    "The following commands should be run **once** at the beginning of your session:\n",
    "\n",
    "```python\n",
    "!pip install -r requirements.txt -qq > /dev/null 2>&1\n",
    "!cat my-private-ca-pcai-1.crt >> $(python -m certifi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26566c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398de57",
   "metadata": {},
   "source": [
    "### Append Custom CA Certificate to Python's Trusted Cert Store\n",
    "\n",
    "The following command appends a custom certificate (`renewed-pcai1-crt.pem`) to Python's certifi CA bundle, allowing Python tools like `requests` to trust internal HTTPS endpoints signed by this CA:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /mnt/shared/ca-renewed/renewed-pcai1-crt.pem >> $(python -m certifi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235051c",
   "metadata": {},
   "source": [
    "### Restart the Kernel\n",
    "\n",
    "After running the setup commands above:\n",
    "\n",
    "Go to the Jupyter menu and select:  \n",
    "**`Kernel` â†’ `Restart Kernel`**  \n",
    "\n",
    "This step is necessary to activate:\n",
    "- The newly installed packages.\n",
    "- The updated CA certificates in the Python runtime.\n",
    "\n",
    "\n",
    "### After Restart: Run the Remaining Notebook Cells\n",
    "\n",
    "Now that the kernel has restarted, begin executing the remaining notebook cells starting from your LangChain and Weaviate imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0197765d-6014-4434-bb59-daf1ea4534cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_classic.text_splitter import CharacterTextSplitter\n",
    "import weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d529650-d181-4dff-a9b5-e2bc2ef62bad",
   "metadata": {},
   "source": [
    "## Fetching the Secret Token for RAG Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a304d1-baba-4586-bd23-bddf732c3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "#getting the auth token\n",
    "secret_file_path = \"/etc/secrets/ezua/.auth_token\"\n",
    "\n",
    "with open(secret_file_path, \"r\") as file:\n",
    "    token = file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb97a8d-2021-4ef5-86fd-66f611bdedf1",
   "metadata": {},
   "source": [
    "## Connecting to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a85b7-022f-43f6-a730-42f73e969422",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \".cluster.local\"\n",
    "http_host = \"weaviate.hpe-weaviate.svc.cluster.local\"\n",
    "grpc_host = \"weaviate-grpc.hpe-weaviate.svc\" + domain\n",
    "weaviate_headers = {\"x-auth-token\": token}\n",
    "#weaviate_headers = {\"x-auth-token\": \"wrong token\"}\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=http_host,        # Hostname for the HTTP API connection\n",
    "    http_port=80,              # Default is 80, WCD uses 443\n",
    "    http_secure=False,           # Whether to use https (secure) for the HTTP API connection\n",
    "    grpc_host=grpc_host,        # Hostname for the gRPC API connection\n",
    "    grpc_port=50051,              # Default is 50051, WCD uses 443\n",
    "    grpc_secure=False,           # Whether to use a secure channel for the gRPC API connection\n",
    "    headers=weaviate_headers,\n",
    "    skip_init_checks=False\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd50eaf-0147-491b-a3f8-50590bee7115",
   "metadata": {},
   "source": [
    "## Connecting to LLM through OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8377065",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_endpoint = \"Paste the endpoint for ollama from Tools & Frameworks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5823f7c-fcc9-439f-9239-9d73c78612a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.3:70b\",\n",
    "    base_url=ollama_endpoint,\n",
    ")\n",
    "llm.invoke(\"which GPU powers the HPE ProLiant Compute DL384 Gen12 ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d1851-c89b-4a96-908d-73978a46498a",
   "metadata": {},
   "source": [
    "## Data Extraction and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74087bad-8c82-4c54-bbd3-033e77ffaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your PDF\n",
    "pdf_path = \"./HPE.pdf\"\n",
    "\n",
    "# Load PDF file\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split into manageable chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "for doc in docs:\n",
    "    doc.metadata={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8b83e-3e1b-48c2-99e3-1ba7d4fab411",
   "metadata": {},
   "source": [
    "## Vector Store Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22599776-f7c7-47fc-84f9-8946f8da9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "vector = WeaviateVectorStore.from_documents(docs, embedding=OllamaEmbeddings(model = \"nomic-embed-text:latest\", base_url=\"https://ollama.pcai1.genai1.hou\"), client=client, index_name=\"RAG\", text_key=\"Rag\".lower() + \"_key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eedbd2-d552-473f-b4b3-69adb44f38c2",
   "metadata": {},
   "source": [
    "## Retriever Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73394d2-b53b-414c-b0dc-a0d86327a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1786bc9-a8a3-49c9-b57a-effdd202942b",
   "metadata": {},
   "source": [
    "## User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a345a03-46b7-4c5d-8dba-86d8ae0f0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"which GPU powers the HPE ProLiant Compute DL384 Gen12 ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7c476-1e68-4797-a428-62a3893e1c4d",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6a4fc-832c-4e02-91aa-a174d8212e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
